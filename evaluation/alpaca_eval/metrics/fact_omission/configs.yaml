# alpaca eval is
weighted_alpaca_eval_gpt4_turbo:
  # prompt_template: "alpaca_eval_clf_gpt4_turbo/alpaca_eval_clf.txt"
  prompt_template: "/users/k/n/kngongiv/Research/private_llm_generation/dialog/evaluation/alpaca_eval/metrics/fact_omission/prompt_fact_omission.txt"
  fn_completions: "openai_completions"
  completions_kwargs:
    model_name: "gpt-4-1106-preview"
    max_tokens: 1
    temperature: 1 # temperature should be applied for sampling, so that should make no effect.
    logprobs: true
    top_logprobs: 5
  fn_completion_parser: "logprob_parser"
  completion_parser_kwargs:
    numerator_token: "m"
    denominator_tokens: ["m", "M"]
    is_binarize: false
  completion_key: "completions_all"
  batch_size: 1